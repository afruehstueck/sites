<!DOCTYPE html>
<html>
<head>
  <title>Experimental GLSL Image Processing</title>
  <link rel="stylesheet" href="glimp.css" />
  <script src='jquery-1.11.0.min.js'></script>
</head>

<body>

<h1>GLSL Image Processing Demo</h1>

<h2>Source Image</h2>
<img id="sourceImage" src="./lion.jpg" width=600></img>

<h2>Processed Image</h2>
<canvas id=renderCanvas width=600 height=400></canvas>

<script id="vertexShader" type="x-shader/x-vertex">
precision highp float;

attribute vec3 coordinate;
attribute vec2 textureCoordinate;

varying vec2 varyingTextureCoordinate;

void main(void) {
  gl_Position = vec4(coordinate,1.);
  varyingTextureCoordinate = textureCoordinate;
}
</script>

<script id="fragmentShader" type="x-shader/x-fragment">
precision highp float;

// GrowCut filter.
//
// GrowCut needs the color input, a strength image (float) and label/mask image (unsigned char).
// On each iteration, there are 3 inputs and 2 outputs.
// Inputs can be handled as separate texture units.
// How do we handle the multiple outputs?
//      1. Each iteration uses two passes through the image. One to compute the new strength. One to compute the new label.
//      2. Stack the two outputs into a vector image, then pull off one field for the final output.
//
// Do we need a general way for an algorithm to specify the types of textures it needs for temporary storage, output, ....?



uniform sampler2D sourceTextureSampler;
uniform vec2 sourceTextureSize;
uniform vec2 focusPoint;

varying vec2 varyingTextureCoordinate;

void main(void) {
  vec4 c = texture2D(sourceTextureSampler, varyingTextureCoordinate);
  vec4 dc = c;

  // only xxx to the right of the mouse
  if (varyingTextureCoordinate.x > focusPoint.x)
  {
    vec3 cc;
    //read out the texels
    for (int i=-1; i <= 1; ++i)
    {
      for (int j=-1; j <= 1; ++j)
      {
        // color at pixel in the neighborhood
        vec2 coord = (varyingTextureCoordinate.xy * sourceTextureSize.xy + vec2(float(i), float(j))) / sourceTextureSize.xy;
        cc = texture2D(sourceTextureSampler, coord).rgb;

        // dilate = max, erode = min
        dc.rgb = max(cc.rgb, dc.rgb); // SWAP IN GROW CUT ALGORITHM
      }
    }
  }

  gl_FragColor = dc;
}

</script>

<script>
'use strict'

var focusPoint = [0., 0.5]; // holds a value to be passed as a uniform to the shader

var sourceTextureSize = [0,0];


//
// set up webgl
//
var renderCanvas = document.querySelector('#renderCanvas');
var gl = renderCanvas.getContext('webgl');
gl.clearColor(0.0, 0.0, 0.0, 1.0); // black, fully opaque
gl.enable(gl.DEPTH_TEST);
gl.depthFunc(gl.LEQUAL); // Near things obscure far things

// buffers for the textured plane in normalized space
var renderImageCoordinatesBuffer = gl.createBuffer();
var renderImageTexureCoordinatesBuffer = gl.createBuffer();
var renderImageVertices = [ -1., -1., 0., 1., -1., 0., -1.,  1., 0., 1.,  1., 0., ];
gl.bindBuffer(gl.ARRAY_BUFFER, renderImageCoordinatesBuffer);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(renderImageVertices), gl.STATIC_DRAW);

var renderImageTextureCoordinates = [ 0, 0,  1, 0,  0, 1,  1, 1 ];
gl.bindBuffer(gl.ARRAY_BUFFER, renderImageTexureCoordinatesBuffer);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(renderImageTextureCoordinates), gl.STATIC_DRAW);

// the source texture
var sourceTextureImage; // = new Image();
var sourceTexture = gl.createTexture();
var setupSourceTexture = function() {
  gl.bindTexture(gl.TEXTURE_2D, sourceTexture);
  gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
  gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, sourceTextureImage);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  //gl.bindTexture(gl.TEXTURE_2D, null); // is this call needed? jvm

  sourceTextureSize[0] = sourceTextureImage.width;
  sourceTextureSize[1] = sourceTextureImage.height;
};

// extra textures and framebuffers for intermediate results of iterative filters and pipelines
var textures = [];
var framebuffers = [];
var setupFrameBuffers = function() {
  for (var ii = 0; ii < 2; ++ii) {
      // create a texture for the framebuffer
      var texture = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_2D, texture);
      //gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true); // do this now at end? or not needed for intermediates? jvm
      gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, sourceTextureImage.width, sourceTextureImage.height, 0,
        gl.RGBA, gl.UNSIGNED_BYTE, null);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
      textures.push(texture);

      // create a framebuffer
      var fbo = gl.createFramebuffer();
      framebuffers.push(fbo);
      gl.bindFramebuffer(gl.FRAMEBUFFER, fbo);

      // attach texture to frame buffer
      gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
    }
}

// the program and shaders
var glProgram = gl.createProgram();
var vertexShader = gl.createShader(gl.VERTEX_SHADER);
gl.shaderSource(vertexShader, document.getElementById("vertexShader").innerHTML);
gl.compileShader(vertexShader);
if (!gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS)) {
  alert('Could not compile vertexShader');
  console.log(gl.getShaderInfoLog(vertexShader));
}
var fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
gl.shaderSource(fragmentShader, document.getElementById("fragmentShader").innerHTML);
gl.compileShader(fragmentShader);
if (!gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS)) {
  alert('Could not compile fragmentShader');
  console.log(gl.getShaderInfoLog(fragmentShader));
}
gl.attachShader(glProgram, vertexShader);
gl.deleteShader(vertexShader);
gl.attachShader(glProgram, fragmentShader);
gl.deleteShader(fragmentShader);
gl.linkProgram(glProgram);

// render a frame
function render() {
  gl.viewport(0, 0, renderCanvas.width, renderCanvas.height);
  gl.clear(gl.COLOR_BUFFER_BIT|gl.DEPTH_BUFFER_BIT);

  gl.useProgram(glProgram);

  // set up the focus point (pointer position)
  gl.uniform2f(gl.getUniformLocation(glProgram, "focusPoint"), focusPoint[0], focusPoint[1]);

  // set up the sourceTextureSize
  gl.uniform2f(gl.getUniformLocation(glProgram, "sourceTextureSize"), sourceTextureSize[0], sourceTextureSize[1]);

  // the sourceTexture
  gl.activeTexture(gl.TEXTURE0);  // bind sourceTexture to texture unit 0
  gl.bindTexture(gl.TEXTURE_2D, sourceTexture);
  gl.uniform1i(gl.getUniformLocation(glProgram, "sourceTextureSampler"), 0); // then, assign sourceTextureSampler to this texture unit

  // the coordinate attribute
  gl.bindBuffer(gl.ARRAY_BUFFER, renderImageCoordinatesBuffer);
  var coordinateLocation = gl.getAttribLocation(glProgram, "coordinate");
  gl.enableVertexAttribArray( coordinateLocation );
  gl.vertexAttribPointer( coordinateLocation, 3, gl.FLOAT, false, 0, 0);

  // the textureCoordinate attribute
  gl.bindBuffer(gl.ARRAY_BUFFER, renderImageTexureCoordinatesBuffer);
  var textureCoordinateLocation = gl.getAttribLocation(glProgram, "textureCoordinate");
  gl.enableVertexAttribArray( textureCoordinateLocation );
  gl.vertexAttribPointer( textureCoordinateLocation, 2, gl.FLOAT, false, 0, 0);

  // (debug - run once. uncomment these lines and set "last" to -1)
  //gl.bindFramebuffer(gl.FRAMEBUFFER, null);
  //gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);


  var last = 3;
  var i;
  for (i=0;i<last;++i)
  {
    // set the frame buffer to render into
    if (i < last-1) {
      // render into one of the texture framebuffers
      gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffers[i%2]);
    } else {
      // use the canvas frame buffer for last render
      gl.bindFramebuffer(gl.FRAMEBUFFER, null);
    }
    //gl.viewport(0, 0, renderCanvas.width, renderCanvas.height); is this needed for the intermediate results?

    // the primitive, triggers the fragment shader
    gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);

    // switch the source texture
    gl.bindTexture(gl.TEXTURE_2D, textures[i % 2]);
  }
}

// once document is loaded, then load images, set up textures and framebuffers, and render
$(function () {
  var images = [];
  var urls = ["./lion.jpg", "./lion_growcut_seeds.jpg"];
  loadImages(urls, onAllImagesLoaded);

  function loadImage(url, callback) {
    var image = new Image();
    image.src = url;
    image.onload = callback;
    return image;
  };

  function loadImages(urls, callback) {
    var imagesToLoad = urls.length;

    var onImageLoad = function() {
      --imagesToLoad;
      if (imagesToLoad == 0) {
        callback(images);
      }
    };

    for (var i=0; i < imagesToLoad; ++i) {
      var image = loadImage(urls[i], onImageLoad);
      images.push(image);
    };
  };

  function onAllImagesLoaded(images) {
    sourceTextureImage = images[0];   // bit hacky to assume the 0th image loaded was the first one we tried to load
    setupSourceTexture(); // jvm - changes these to take image as parameter? change these to keep things as fields in image[i]?
    setupFrameBuffers(); // jvm - grow cut needs 1 float image (strength) and 1 unsigned char image (mask) on input and output -> 4 buffers are needed
    render();
  };

  // pass the mouse location as a uniform variable to the fragment shader
  var updateFocus = function(event) {
    focusPoint = [event.offsetX / images[0].width, 1. - (event.offsetY / images[0].height)];
    render();
  };
  $('#renderCanvas').mousedown(updateFocus);
  $('#renderCanvas').mousemove(updateFocus);
});

</script>

<p>
Move pointer over lower image.
<br>
Check out <a href='https://github.com/pieper/sites/tree/gh-pages/glimp'>the source code</a>.
</p>

<p>
This demo uses WebGL.  Not all devices and browsers are supported.
</p>

</body>
</html>
